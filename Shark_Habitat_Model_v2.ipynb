{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25355486",
   "metadata": {},
   "source": [
    "# Shark Habitat & Movement Model — v2 (expanded drivers + apps)\n",
    "\n",
    "This version adds **eddy polarity**, **EKE**, **SST fronts**, **distance to eddy core/edge**, **bathymetry + distance to shelf break**, and **mixed layer depth (MLD)** to the habitat model. It also ships a **Streamlit** and a **Bokeh** dashboard (see project folder) for interactive exploration.\n",
    "\n",
    "**Tip:** All fields are easily swappable with real **SWOT (SSH)**, **MODIS/PACE (Chl)**, and **SST** arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6272eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports & setup\n",
    "import math, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the environment bundle prepared for this notebook (or replace with your own)\n",
    "env = np.load(\"/mnt/data/env_fields_v2.npz\")\n",
    "lons = env[\"lons\"]; lats = env[\"lats\"]\n",
    "SSH = env[\"SSH\"]; U = env[\"U\"]; V = env[\"V\"]; SPEED = env[\"SPEED\"]\n",
    "SST = env[\"SST\"]; CHL = env[\"CHL\"]\n",
    "W = env[\"W\"]; EDDY_CORE_MASK = env[\"EDDY_CORE_MASK\"].astype(bool); EDDY_EDGE_MASK = env[\"EDDY_EDGE_MASK\"].astype(bool)\n",
    "WARM_MASK = env[\"WARM_MASK\"].astype(bool)\n",
    "EKE = env[\"EKE\"]; SST_FRONT = env[\"SST_FRONT\"]\n",
    "BATHY = env[\"BATHY\"]; SHELF_MASK = env[\"SHELF_MASK\"].astype(bool)\n",
    "MLD = env[\"MLD\"]\n",
    "DIST_TO_CORE_M = env[\"DIST_TO_CORE_M\"]; DIST_TO_EDGE_M = env[\"DIST_TO_EDGE_M\"]; DIST_TO_SHELF_M = env[\"DIST_TO_SHELF_M\"]\n",
    "\n",
    "LAT_MIN = float(env[\"LAT_MIN\"]); LAT_MAX = float(env[\"LAT_MAX\"])\n",
    "LON_MIN = float(env[\"LON_MIN\"]); LON_MAX = float(env[\"LON_MAX\"])\n",
    "dx_m = float(env[\"dx_m\"]); dy_m = float(env[\"dy_m\"]); f = float(env[\"f\"]); g = float(env[\"g\"])\n",
    "\n",
    "NY, NX = SSH.shape\n",
    "LON, LAT = np.meshgrid(lons, lats)\n",
    "\n",
    "def bilinear(field2d, lon, lat):\n",
    "    # Safe bilinear interpolation on our regular grid\n",
    "    lon = np.clip(lon, lons[0], lons[-1]); lat = np.clip(lat, lats[0], lats[-1])\n",
    "    ix = np.searchsorted(lons, lon) - 1; iy = np.searchsorted(lats, lat) - 1\n",
    "    ix = np.clip(ix, 0, NX-2); iy = np.clip(iy, 0, NY-2)\n",
    "    x0, x1 = lons[ix], lons[ix+1]; y0, y1 = lats[iy], lats[iy+1]\n",
    "    wx = (lon - x0) / (x1 - x0 + 1e-12); wy = (lat - y0) / (y1 - y0 + 1e-12)\n",
    "    f00 = field2d[iy, ix]; f10 = field2d[iy, ix+1]; f01 = field2d[iy+1, ix]; f11 = field2d[iy+1, ix+1]\n",
    "    return (1-wx)*(1-wy)*f00 + wx*(1-wy)*f10 + (1-wx)*wy*f01 + wx*wy*f11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb251bda",
   "metadata": {},
   "source": [
    "### Visual checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77364a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"SSH anomaly [m] & eddy cores (x)\")\n",
    "plt.imshow(SSH, origin='lower', extent=[LON_MIN, LON_MAX, LAT_MIN, LAT_MAX])\n",
    "yy, xx = np.where(EDDY_CORE_MASK); sel = (np.arange(yy.size) % 30) == 0\n",
    "plt.scatter(lons[xx[sel]], lats[yy[sel]], s=10, marker='x')\n",
    "plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"SST fronts |∇SST|\")\n",
    "plt.imshow(SST_FRONT, origin='lower', extent=[LON_MIN, LON_MAX, LAT_MIN, LAT_MAX])\n",
    "plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"EKE [m$^2$ s$^{-2}$]\")\n",
    "plt.imshow(EKE, origin='lower', extent=[LON_MIN, LON_MAX, LAT_MIN, LAT_MAX])\n",
    "plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"Bathymetry [m] & 200 m shelf break (dots)\")\n",
    "plt.imshow(BATHY, origin='lower', extent=[LON_MIN, LON_MAX, LAT_MIN, LAT_MAX])\n",
    "yy, xx = np.where(SHELF_MASK); sel = (np.arange(yy.size) % 50) == 0\n",
    "plt.scatter(lons[xx[sel]], lats[yy[sel]], s=8)\n",
    "plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9c8d1",
   "metadata": {},
   "source": [
    "### Tag ingest / simulation (replace with your live tag feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584367c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here we re-use the synthetic tag if present, otherwise generate one.\n",
    "tag_csv = Path('/mnt/data/example_tag_data.csv')\n",
    "if tag_csv.exists():\n",
    "    tag_df = pd.read_csv(tag_csv, parse_dates=['time'])\n",
    "else:\n",
    "    # simple seed track if the CSV isn't there\n",
    "    rng = np.random.default_rng(1)\n",
    "    n_steps, dt_hours = 120, 6.0\n",
    "    dt = dt_hours*3600.0\n",
    "    lon, lat = -71.0, 35.5\n",
    "    track = []\n",
    "    for k in range(n_steps):\n",
    "        u = bilinear(U, lon, lat); v = bilinear(V, lon, lat)\n",
    "        lon += (u*dt)/dx_m + 0.02*rng.normal()\n",
    "        lat += (v*dt)/dy_m + 0.02*rng.normal()\n",
    "        lon = float(np.clip(lon, LON_MIN, LON_MAX)); lat = float(np.clip(lat, LAT_MIN, LAT_MAX))\n",
    "        depth = 200.0\n",
    "        t = pd.Timestamp('2025-05-01') + pd.to_timedelta(k*dt_hours, unit='h')\n",
    "        track.append([t, lon, lat, depth, u, v])\n",
    "    tag_df = pd.DataFrame(track, columns=['time','lon','lat','depth_m','u_ms','v_ms'])\n",
    "    tag_df.to_csv(tag_csv, index=False)\n",
    "\n",
    "print(tag_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94b38e",
   "metadata": {},
   "source": [
    "### Expanded features & HSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build feature extraction, now including the new drivers\n",
    "def extract_features(lon_pts, lat_pts):\n",
    "    vals = []\n",
    "    for lo, la in zip(lon_pts, lat_pts):\n",
    "        sst = bilinear(SST, lo, la)\n",
    "        chl = bilinear(CHL, lo, la)\n",
    "        ssh = bilinear(SSH, lo, la)\n",
    "        eke = bilinear(EKE, lo, la)\n",
    "        fr = bilinear(SST_FRONT, lo, la)\n",
    "        bathy = bilinear(BATHY, lo, la)\n",
    "        mld = bilinear(MLD, lo, la)\n",
    "        # distances (meters)\n",
    "        d_core = bilinear(DIST_TO_CORE_M, lo, la)\n",
    "        d_edge = bilinear(DIST_TO_EDGE_M, lo, la)\n",
    "        d_shelf = bilinear(DIST_TO_SHELF_M, lo, la)\n",
    "        # preferences / proximities\n",
    "        sst_pref = math.exp(-((sst - 22.0)/2.5)**2)\n",
    "        chl_pref = math.exp(-((chl - 0.45)/0.25)**2)\n",
    "        mld_pref = math.exp(-((mld - 40.0)/15.0)**2)\n",
    "        # proximity kernels (meters -> unitless 0..1)\n",
    "        def prox(d, L=80000.0):  # 80 km e-folding\n",
    "            return math.exp(-max(d, 0.0)/L)\n",
    "        core_prox = prox(d_core, 60000.0)\n",
    "        edge_prox = prox(d_edge, 50000.0)\n",
    "        shelf_prox = prox(d_shelf, 30000.0)\n",
    "        vals.append([sst, chl, ssh, eke, fr, bathy, mld, d_core, d_edge, d_shelf,\n",
    "                     sst_pref, chl_pref, mld_pref, core_prox, edge_prox, shelf_prox])\n",
    "    arr = np.array(vals, dtype=float)\n",
    "    # standardize continuous physical magnitudes (first 10 columns)\n",
    "    mu = arr[:, :10].mean(axis=0); sig = arr[:, :10].std(axis=0) + 1e-9\n",
    "    arr[:, :10] = (arr[:, :10] - mu) / sig\n",
    "    return arr, mu, sig\n",
    "\n",
    "# Case-control (used vs available endpoints)\n",
    "used_lon = tag_df['lon'].values[1:]\n",
    "used_lat = tag_df['lat'].values[1:]\n",
    "n = used_lon.size\n",
    "K = 5  # available per used\n",
    "rng = np.random.default_rng(2)\n",
    "avail_lon, avail_lat = [], []\n",
    "for i in range(n):\n",
    "    lo0, la0 = tag_df['lon'].values[i], tag_df['lat'].values[i]\n",
    "    props_lo = lo0 + 0.6*np.random.normal(size=K)\n",
    "    props_la = la0 + 0.6*np.random.normal(size=K)\n",
    "    props_lo = np.clip(props_lo, LON_MIN, LON_MAX)\n",
    "    props_la = np.clip(props_la, LAT_MIN, LAT_MAX)\n",
    "    avail_lon.append(props_lo); avail_lat.append(props_la)\n",
    "avail_lon = np.array(avail_lon).reshape(-1); avail_lat = np.array(avail_lat).reshape(-1)\n",
    "\n",
    "X_used, mu, sig = extract_features(used_lon, used_lat)\n",
    "X_av, _, _ = extract_features(avail_lon, avail_lat)\n",
    "\n",
    "X = np.vstack([X_used, X_av])\n",
    "y = np.hstack([np.ones(X_used.shape[0]), np.zeros(X_av.shape[0])])\n",
    "\n",
    "# Add intercept\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "def fit_logit_newton(X, y, lam=1e-2, max_iter=80):\n",
    "    w = np.zeros(X.shape[1])\n",
    "    for _ in range(max_iter):\n",
    "        z = X @ w\n",
    "        p = 1 / (1 + np.exp(-z))\n",
    "        W = p * (1 - p)\n",
    "        grad = X.T @ (y - p) - lam * w\n",
    "        H = -(X.T * W) @ X - lam * np.eye(X.shape[1])\n",
    "        try:\n",
    "            step = np.linalg.solve(H, grad)\n",
    "        except np.linalg.LinAlgError:\n",
    "            step = np.linalg.pinv(H) @ grad\n",
    "        w_new = w - step\n",
    "        if np.linalg.norm(w_new - w) < 1e-6:\n",
    "            w = w_new; break\n",
    "        w = w_new\n",
    "    return w\n",
    "\n",
    "coef = fit_logit_newton(X, y, lam=2e-2, max_iter=120)\n",
    "print(\"Coefficients length:\", coef.shape[0])\n",
    "\n",
    "def hsi_prob(lon, lat, coef, mu, sig):\n",
    "    # recompute feature vector at a single point, then logistic probability\n",
    "    sst = bilinear(SST, lon, lat); chl = bilinear(CHL, lon, lat); ssh = bilinear(SSH, lon, lat)\n",
    "    eke = bilinear(EKE, lon, lat); fr = bilinear(SST_FRONT, lon, lat)\n",
    "    bathy = bilinear(BATHY, lon, lat); mld = bilinear(MLD, lon, lat)\n",
    "    d_core = bilinear(DIST_TO_CORE_M, lon, lat); d_edge = bilinear(DIST_TO_EDGE_M, lon, lat); d_shelf = bilinear(DIST_TO_SHELF_M, lon, lat)\n",
    "    sst_pref = math.exp(-((sst - 22.0)/2.5)**2)\n",
    "    chl_pref = math.exp(-((chl - 0.45)/0.25)**2)\n",
    "    mld_pref = math.exp(-((mld - 40.0)/15.0)**2)\n",
    "    def prox(d, L=80000.0): return math.exp(-max(d, 0.0)/L)\n",
    "    core_prox = prox(d_core, 60000.0); edge_prox = prox(d_edge, 50000.0); shelf_prox = prox(d_shelf, 30000.0)\n",
    "    arr = np.array([sst, chl, ssh, eke, fr, bathy, mld, d_core, d_edge, d_shelf,\n",
    "                    sst_pref, chl_pref, mld_pref, core_prox, edge_prox, shelf_prox], dtype=float)\n",
    "    # standardize first 10 physical magnitudes\n",
    "    arr[:10] = (arr[:10] - mu) / sig\n",
    "    x = np.hstack([1.0, arr])  # intercept\n",
    "    z = float(x @ coef)\n",
    "    return 1.0 / (1.0 + math.exp(-z))\n",
    "\n",
    "# Build a gridded HSI\n",
    "HSI = np.zeros_like(SSH)\n",
    "for j in range(SSH.shape[0]):\n",
    "    for i in range(SSH.shape[1]):\n",
    "        HSI[j, i] = hsi_prob(lons[i], lats[j], coef, mu, sig)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"Fitted Habitat Suitability (with expanded drivers)\")\n",
    "plt.imshow(HSI, origin='lower', extent=[LON_MIN, LON_MAX, LAT_MIN, LAT_MAX])\n",
    "plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8fd96",
   "metadata": {},
   "source": [
    "### Forecast with expanded HSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forecast parameters\n",
    "dt_hours = 6.0; dt = dt_hours*3600.0\n",
    "N_fore = 24; N_ens = 40\n",
    "\n",
    "last_lon = float(tag_df['lon'].values[-1]); last_lat = float(tag_df['lat'].values[-1])\n",
    "\n",
    "def predict_traj(lon0, lat0, coef, mu, sig, seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    traj = [(lon0, lat0)]\n",
    "    vx_prev, vy_prev = 0.0, 0.0\n",
    "    for _ in range(N_fore):\n",
    "        u = bilinear(U, lon0, lat0); v = bilinear(V, lon0, lat0)\n",
    "        eps = 0.02\n",
    "        # finite-diff gradient of HSI probability\n",
    "        h_e = hsi_prob(min(lon0+eps, LON_MAX), lat0, coef, mu, sig)\n",
    "        h_w = hsi_prob(max(lon0-eps, LON_MIN), lat0, coef, mu, sig)\n",
    "        h_n = hsi_prob(lon0, min(lat0+eps, LAT_MAX), coef, mu, sig)\n",
    "        h_s = hsi_prob(lon0, max(lat0-eps, LAT_MIN), coef, mu, sig)\n",
    "        dhdx = (h_e - h_w) / (2*eps*dx_m); dhdy = (h_n - h_s) / (2*eps*dy_m)\n",
    "        bias_u = +500.0 * dhdx; bias_v = +500.0 * dhdy\n",
    "        vx_m = 0.6*(u + bias_u) + 0.3*vx_prev + 0.05*rng.normal()\n",
    "        vy_m = 0.6*(v + bias_v) + 0.3*vy_prev + 0.05*rng.normal()\n",
    "        lon0 += (vx_m * dt) / dx_m; lat0 += (vy_m * dt) / dy_m\n",
    "        lon0 = float(np.clip(lon0, LON_MIN, LON_MAX)); lat0 = float(np.clip(lat0, LAT_MIN, LAT_MAX))\n",
    "        vx_prev, vy_prev = vx_m, vy_m\n",
    "        traj.append((lon0, lat0))\n",
    "    return np.array(traj)\n",
    "\n",
    "trajectories = [predict_traj(last_lon, last_lat, coef, mu, sig, i) for i in range(N_ens)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"Observed (tail) and Forecast Ensemble over HSI\")\n",
    "plt.imshow(HSI, origin='lower', extent=[LON_MIN, LON_MAX, LAT_MIN, LAT_MAX])\n",
    "tail = tag_df.tail(16)\n",
    "plt.plot(tail['lon'].values, tail['lat'].values)\n",
    "for tr in trajectories:\n",
    "    plt.plot(tr[:,0], tr[:,1], linewidth=0.8, linestyle='--')\n",
    "plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\"); plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
